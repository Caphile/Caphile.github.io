---
title: SNaiL
layout: default
parent: Projects
---

# SNaiL
{: .no_toc }

<br/>
AI 기반 아동 인지능력 검사 서비스

2023 데이터청년캠퍼스 한국외국어대학교 주관 자연어처리 기반 딥러닝기술 융합과정

<b>한국외국어대학교 내 3위 작품<b/>

<br/>
팀 구성

![image](https://user-images.githubusercontent.com/137850633/262909874-f29f9a16-f8fa-47ed-92eb-5ca45d70e0d4.png)

---

## Contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## 소개

### 개발동기
{: .no_toc}

<br/>
아동의 인지 발달에 관심이 많은 부모님들을 위해 SNaiL을 개발하게 되었다. 아동의 인지 발달은 그들의 학습, 사회성, 적응력 등에 영향을 미치는 중요한 요소인데, 현재 시중에 있는 인지 발달 검사는 비용이 비싸고, 시간이 오래 걸리고, 전문가의 도움이 필요한 경우가 많았다. 이런 문제점들로 인해 부모님들은 아동의 인지 발달 수준을 쉽게 알 수 없고, 적절한 피드백도 받기 어렵다는 생각이 들었다.

이러한 문제점을 해결하고자 SNaiL을 개발했는데, SNaiL은 모바일 기기만 있으면 언제 어디서나 인지 발달 검사를 할 수 있으며, AI 기술을 활용하여 정확하고 신뢰할 수 있는 결과를 제공한다. 또한 AI 피드백을 통해 부모님들이 아동의 인지 발달 수준과 특징을 이해하고, 보완할 점을 알 수 있도록 도와준다.

이 서비스는 부모님들이 Snail을 통해 아동의 인지 발달에 대한 관심과 지식을 높이고, 아동의 성장과 꿈을 응원하고 지원할 수 있도록 하는 것을 목표로 제작되었다.
<br/><br/>

### 개발목표
{: .no_toc}

<br/>
SNaiL을 개발함에 있어 아래의 5가지 핵심 가치를 중요하게 고려하여 목표를 설정했다.

- <b>접근성:</b> 모바일 기기만 있으면 언제 어디서나 인지 발달 검사를 할 수 있도록 하여 금전적, 시공간적 부담을 줄인다.
- <b>신뢰성:</b> 신뢰도와 타당도가 확보된 검사 도구를 사용하고, AI 기술을 활용하여 정확하고 객관적인 결과를 제공한다.
- <b>다양성:</b> 아동의 인지 발달에 영향을 미치는 다양한 역량(유연성, 주의력, 기억력, 처리 능력, 언어 능력)을 평가할 수 있는 다양한 검사를 제공한다.
- <b>편리성:</b> 아동의 음성과 시선을 이용하여 검사를 진행하므로 복잡한 조작이 필요하지 않다.
- <b>유익성:</b> AI 피드백을 통해 부모님들이 아동의 인지 발달 수준과 특징을 이해하고, 보완할 점을 알 수 있도록 도와준다.
<br/><br/>

### 추진배경
{: .no_toc}

<br/>
SNaiL을 개발하기에 앞서 다음과 같은 배경을 조사했다.

- <b>아동 인지 발달에 대한 관심 증가:</b> 최근에 아동의 인지 발달에 대한 관심이 크게 높아진 상태였고, 특히 코로나 19 팬데믹으로 인해 아동들의 발달이 뒤처질 수 있는 우려가 커지고 있었다. 조사 결과에 따르면, 부모의 70%가 코로나 19가 아동 발달에 영향을 미칠 것으로 생각하고 있었다. 또한 코로나 19와 관련된 실태 조사에 따르면, 어린이집 아동의 거의 절반 및 가정 양육 아동의 30%가 도움이 필요한 수준임을 밝히는 등의 자료들도 쉽게 찾을 수 있었다.

- <b>인지 발달 검사의 문제점:</b> 현재 시중에 있는 인지 발달 검사는 몇 가지 문제점을 가지고 있는데, 비용이 높아 부담스럽다는 점, 검사에 상당한 시간이 소요되며 아동의 집중력 유지와 부모의 시간 관리에 어려움을 줄 수 있다는 점, 전문가의 지원 없이는 해석에 어려움을 겪게 점 등이 있었다.

- <b>AI 기술의 활용 가능성:</b> 인공지능 기술은 인지 발달 검사에 다양하게 활용될 수 있다. 이 서비스에 적용된 인공지능 기술을 예로 들면, 음성 및 시선을 통한 검사, AI 기반 피드백을 통한 결과 해석 등이 있겠다. 이러한 기술은 검사의 비용과 시간을 줄이는 데 도움을 주며, 부모들이 아동의 발달 상황을 더 잘 이해할 수 있도록 지원한다.

이러한 배경을 바탕으로 SNaiL이 개발되었다. SNaiL은 부모들이 간편하게 아동의 인지 발달을 평가하고 AI 기술을 통해 정확하고 유익한 결과를 얻을 수 있는 서비스다.
<br/><br/>

---

## 개요

### 진행과정
{: .no_toc}

![image](https://github.com/Caphile/Caphile.github.io/assets/47132589/8d5f149b-ec39-4cad-a35e-276b2fdc4333)

### 시스템 구조도
{: .no_toc}

![image](https://github.com/Caphile/Caphile.github.io/assets/47132589/61564222-9178-416e-bae8-9f21d0250a4f)

### 서비스 플로우
{: .no_toc}

![image](https://github.com/Caphile/Caphile.github.io/assets/47132589/dedee876-1911-40a7-8bb5-220d46d56429)

### 화면구성
{: .no_toc}
- 검사화면

![image](https://github.com/Caphile/Caphile.github.io/assets/47132589/a2139e50-4d06-410e-99a3-d86b9c7cbe38)

- 결과화면

![image](https://github.com/Caphile/Caphile.github.io/assets/47132589/9c200c19-c38d-473e-b70e-2405875f7a70)


---

## 개발

<br/>
### <b>Backend<b/>

#### 개발환경
{: .text-gamma}
{: .no_toc}
{: .new }
> Server : AWS EC2(Node.js, Flask)
>
> DB : AWS RDS/MariaDB

배포를 고려하여 프로젝트를 계획했기 때문에 클라우드 환경의 서버가 필요했다. 여러 클라우드 서버 옵션을 비교해 보고, AWS의 서비스가 가장 적합하다고 판단했다. 조건부로 프리티어 서버를 무료로 사용 가능하며 사용자가 많아 관련 자료가 많다는 점이 매력적으로 작용했다.

#### 클라우드 서버
{: .text-gamma}
{: .no_toc}
<br/>
사용의 주요 목적은 서비스와 AI 모델 및 데이터베이스 간의 연결을 위한 REST API를 원격 서버를 통해 구현하는 것이었다. 초기 설계 단계에서는 REST API를 Flutter 서비스에 내장하여 사용하려고 했으나 호환성 문제로 인해 데이터를 서버에서 요청하고 가져오는 방식으로 변경하게 되었다. AI 모델의 튜닝 및 운영은 Python을 사용하였고, 데이터베이스 연동 및 외부 API 사용을 위해 JS를 활용했기 때문에, Flask와 Node.js를 각각 다른 포트에서 실행하여 통신했다. 이때, EC2 인스턴스의 엔드포인트 주소가 "ec2-OO-OOO-OOO-OO.ap-northeast-2.compute.amazonaws.com"와 같이 복잡하기 때문에 도메인을 구하여 쉽게 접근할 수 있도록 설정했다. 프티티어 서버를 사용하기 떄문에 부족한 물리 메모리는 Swap 메모리를 활용했다.

#### 데이터베이스
{: .text-gamma}
{: .no_toc}
<br/>
AWS RDS로, MariaDB 엔진을 사용했다. 서버 인스턴스와 DB인스턴스는 같은 AWS 서비스이다보니 쉽게 연결이 가능했다. 다음은 DB Table 설계이다.
기본적으로 부모, 아동, 검사에 관한 정보를 저장하는 테이블 3개로 DB를 구성했다. 

- PARENT

    | USER_ID | USER_PW | PARENT_ID |
    | --- | --- | --- |
    | VARCHAR(20) | VARCHAR(20) | CHAR(8) |
    | NOT NULL | NOT NULL | PRIMARY |

- CHILD    

    | PARENT_ID | CHILD_ID | NAME | SEX | BIRTH | IMG |
    | --- | --- | --- | --- | --- | --- |
    | CHAR(8) | CHAR(8) | VARCHAR(5) | BOOL | DATE | INT |
    | NOT NULL | PRIMARY | NOT NULL |  |  |  |

- RESULT

    | RESULT_ID | TEST_DATE | EYETRACT | STROOP | IMG_DESC | VOCA_RP | LINE | SENTENCE | CHOSUNG | FEEDBACK | CHILD_ID |
    | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
    | CHAR(8) | DATE | FLOAT(5,2) | FLOAT(5,2) | FLOAT(5,2) | FLOAT(5,2) | FLOAT(5,2) | FLOAT(5,2) | FLOAT(5,2) | VARCHAR(500) | CHAR(8) |
    | PRIMARY | NOT NULL |  |  |  |  |  |  |  |  | NOT NULL |


#### 웹 호스팅
{: .text-gamma}
{: .no_toc}
<br/>
Github Page를 사용해 배포했다. Flutter는 build web 명령어를 통해 쉽게 웹 환경을 구성할 수 있는 기능을 제공해준다. 빌드된 소스들을 Github에 올리고 새로운 도메인인 [web.snail23.kro.kr](https://web.snail23.kro.kr/)를 가져와 적용했다. 현재도 접속은 가능하지만 금전적인 이유로 더이상 AWS 서버를 구동하지 않고 있기 떄문에, DB 접근이나 Api 사용 등이 불가능해 완전하지 못한 상태이다.

<br/>
### <b>Frontend<b/>

#### 개발환경
{: .text-gamma}
{: .no_toc}
{: .new }
> Flutter, Figma

와이어프레임 작성, 에셋 디자인 등은 Figma를 통해 진행했고, 서비스에 실제 사용될 UI 화면은 Flutter로 작성했다. Fimga 플러그인 중 Figma에서 그린 프레임을 Flutter 코드로 바꿔주는 Figma to Code를 사용했는데, Figma 사용경험이 적은 우리팀의 개발자들이 UI 화면을 구현하는데 많은 도움을 받았다.

기능은 크게 세 파트로 기초 정보, 검사, 결과로 나누어 개발을 진행했다. 아래 자료는 프로젝트 당시 사용한 Figma 화면의 일부이다.

![image](https://github.com/home-gravity/home-gravity.github.io/assets/47132589/657cf0af-1787-4c0d-9d92-63fdd1bdb27b)

#### 기초정보
{: .text-gamma}
{: .no_toc}
<br/>
서비스의 시작화면으로 사용한 스플래쉬 화면부터 검사 가이드 시작 전 화면까지 구성되어있다.
1. 스플래쉬
2. 회원가입 및 로그인
3. 아동 관리 및 선택: 아동의 정보를 추가/ 수정/삭제하거나, 검사를 시작/지난결과 조회를 위한 아동의 선택이 이루어짐.

#### 검사
{: .text-gamma}
{: .no_toc}
<br/>
실질적인 검사 및 검사 가이드가 구성되어있다.
1. 검사 통합 가이드: 웹캠과 마이크를 활용해야 하므로 관련 권한을 요청하고, 기능이 정상 작동하는지 확인.
2. 여러가지 검사 및 가이드: 이 글의 작성 시점 기준으로 총 5개(스트룹, 단어 유창성, 선로 잇기, 단어 따라 말하기, 이야기 이해)의 검사로 이루어져 있으며, 검사 시작 전에 약 10초간 검사에 대해 설명하는 가이드가 포함됨.

#### 결과
{: .text-gamma}
{: .no_toc}
<br/>
검사가 종료된 후 얻은 점수를 바탕으로 여러가지 상대지표들을 확인 할 수 있다.
1. 검사 결과 저장: 검사 결과와 점수를 이용하여 GPT 피드백을 생성하고 결과를 저장.
2. 검사 결과: 선택한 RESULT_ID를 기준으로 해당 검사의 결과를 확인.
3. 검사 결과(대시보드): 여러 달에 걸쳐 인지 능력 지표의 변화를 한눈에 확인할 수 있는 대시보드를 제공.

유연성, 주의력, 기억력, 처리능력, 언어능력과 같은 다양한 능력을 측정한 이전 검사 결과를 기반으로 통계를 생성하여 자신의 능력치의 백분위를 파악할 수 있습니다. 각 점수를 종합하여 통합 백분위를 얻어내어, 아동이 상대적으로 어느 정도의 인지능력을 가지고 있는지를 판단할 수 있다.

DB에 결과 데이터가 쌓인 모습

![image](https://github.com/home-gravity/home-gravity.github.io/assets/47132589/d62ed3ae-c321-42f7-bb46-bff50c9274f1)

<br/>
### <b>Modeling<b/>

#### 개발환경
{: .text-gamma}
{: .no_toc}
{: .new }
> Python

기본적으로 Python을 사용하여 AI 모델을 준비했고, Flutter 어플리케이션 내에서 Python을 구동하기에는 무리가 있어 Flask 서버를 두어 Api 통신으로 모델을 활용했다.

#### 음성인식
{: .text-gamma}
{: .no_toc}
<br/>
어떤 모델을 사용할지 선택하기 위해 많은 고민들이 따랐다. AI Hub에 있는 발화데이터로 우리만의 모델을 새로 만들거나 혹은 기존에 좋은 성능을 자랑하는 Whisper 모델을 튜닝하여 사용하거나, Flutter에 존재하는 모듈을 사용하는 방법 등이 있었다.



#### 시선추적
{: .text-gamma}
{: .no_toc}
<br/>
얼굴 이미지에서 눈동자의 위치를 추적하고, 눈동자가 어떤 방향을 향하고 있는지를 판단하는 함수를 작성하여 구현하였다. [shape_predictor_68_face_landmarks.dat](https://github.com/italojs/facial-landmarks-recognition)은 얼굴을 감지하고 얼굴의 특징점을 예측하는 데 사용되는 데이터 파일인데, 얼굴 이미지에서 68개의 랜드마크를 감지할 수 있다. 

```python
# 랜드마크 추출
landmarks = predictor(img, face)

# 왼쪽 눈 위치 찾기
left_eye_x = min(landmarks.part(n).x for n in range(36, 42))
left_eye_y = min(landmarks.part(n).y for n in range(36, 42))
left_eye_w = max(landmarks.part(n).x for n in range(36, 42)) - left_eye_x
left_eye_h = max(landmarks.part(n).y for n in range(36, 42)) - left_eye_y
```

위 코드서 알 수 있듯 36번부터 41번 랜드마크가 왼쪽 눈을 표현한다. 여기에서 알게 된 양 눈의 좌표를 바탕으로 눈 이미지만 따로 떼어내어 그레이 스케일로 변환 후 가우시안 블러를 적용하여 특정 임계값(50)을 기준으로 눈동자를 찾았다. 

 ```python
# 눈 영역 설정
roi_left_eye = img[left_eye_y:left_eye_y+left_eye_h, left_eye_x:left_eye_x+left_eye_w]

# 왼쪽 눈 처리
gray_roi_left_eye = cv2.cvtColor(roi_left_eye, cv2.COLOR_BGR2GRAY)
gray_roi_left_eye = cv2.GaussianBlur(gray_roi_left_eye, (5,5), 0)

_, threshold_left_eye = cv2.threshold(gray_roi_left_eye, 50, 255, cv2.THRESH_BINARY_INV)
contours_left_eye, _ = cv2.findContours(threshold_left_eye, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
contours_left_eye = sorted(contours_left_eye, key=lambda x: cv2.contourArea(x), reverse=True)
```

위 코드에서는 왼쪽 눈에 대한 처리만 했지만 오른쪽 눈의 랜드마크 범위를 42부터 48로 설정한 것을 제외하고는 동일하게 진행했다. 이 과정을 통하면 다음 자료와 같이 눈과 눈동자의 실시간 추적이 가능함을 볼 수 있다.


이때 얻어낸 


#### AI 피드백
{: .text-gamma}
{: .no_toc}
<br/>
초기에는 구상하지 않다가 경쟁력 등의 문제로 프로젝트 말미에 추가하는것으로 결정되어 

---

## 결과

프로젝트를 통해 아동 인지 발달 검사 서비스인 SNaiL을 성공적으로 개발했으며 주요 결과와 성과는 다음과 같다.

#### 주요 성과
{: .text-gamma}
{: .no_toc}
- <b>접근성 확보:</b> 모바일 기기로 시간 장소 상관없이 인지 발달 검사를 수행할 수 있도록 하여 부모님들의 금전적, 시간적 부담을 축소.

- <b>신뢰성과 정확성:</b> 신뢰도와 타당성이 검증된 검사 도구를 사용하고, AI 기술을 활용하여 정확하고 객관적인 결과를 부모님들에게 제공.

- <b>다양한 역량 평가:</b> 아동의 인지 발달에 영향을 미치는 다양한 역량(유연성, 주의력, 기억력, 처리 능력, 언어 능력)을 평가할 수 있는 다양한 검사 제공.

- <b>편리성 강화:</b> 아동의 음성과 시선을 활용하므로 어려운 조작 없이 검사 진행 가능.

- <b>AI 피드백:</b> AI 기반 맞춤 피드백을 통해 부모님에게 아동의 인지 발달 수준과 특징에 대한 이해 및 보완할 수 있는 가이드 제공.

#### 향후 계획
{: .text-gamma}
{: .no_toc}
- <b>전문가와의 연계 강화:</b> 앞으로 의료 기관과 전문가와의 연계를 통해 검사의 신뢰성과 타당성을 더욱 높이고, 검사 결과를 통해 전문가와의 상담 서비스 제공.

- <b>다양한 연령층 대상 확장:</b> 3-5세 어린이만을 대상으로 하는 현재 서비스를 확장하여 다양한 연령층에 대한 검사 기능을 추가하고, 이를 통해 ADHD나 치매 등의 질환 의심을 제안하는 등의 시장성 확장.

- <b>역량별 검사 확대:</b> 각 역량 별로 더 세부적이고 다양한 검사들을 추가해, 특정 역량에 대한 심도 있는 검사를 진행할 수 있도록 서비스를 확대.

SNaiL은 아동 인지 발달에 대한 관심과 지식을 높이며, 아동의 성장과 꿈을 응원하고 지원할 수 있는 서비스다. 아동과 부모님들이 함께 성장하는 과정에서 SNaiL은 계속해서 발전하고 확장 가능할 것으로 판단된다.

